# Example training configuration for therapy RL agent
# This file demonstrates how to configure training parameters

experiment_name: cold_stuck_ppo_baseline

# Environment parameters
patterns:
  - cold_stuck
  - dominant_stuck
mechanism: frequency_amplifier
threshold: 0.8
max_sessions: 100
entropy: 0.5
bond_alpha: null  # Use config.BOND_ALPHA
bond_offset: 0.7
history_weight: 1.0
enable_parataxic: true
baseline_accuracy: 0.5

# RL parameters (PPO)
total_timesteps: 500000
n_envs: 8
learning_rate: 0.0003
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01

# Network architecture
hidden_size: 256
lstm_hidden_size: 128

# Logging and checkpointing
log_dir: logs/cold_stuck_baseline
save_freq: 10000
eval_freq: 5000
eval_episodes: 100
seed: 42
