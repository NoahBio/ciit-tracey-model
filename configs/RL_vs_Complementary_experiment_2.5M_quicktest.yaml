# RL vs Complementary Therapist Benchmark - QUICK TEST VERSION
# Baseline: Complementary strategy achieves 18% success rate (18/100 seeds)
# Task: cold_stuck pattern with frequency_amplifier mechanism
# Challenge: bond_alpha=5.0 (high bond influence), threshold=0.8 (80th percentile)
# Goal: Validate that RL can learn basic strategies (initial test run)
#
# Configuration matches baseline experiment exactly:
# - cold_stuck pattern with frequency_amplifier
# - threshold=0.8, entropy=0.1, bond_alpha=5.0
# - 100-session episodes with 50% perceptual accuracy
#
# Training: 2.5M timesteps (~10 hours) - Quick validation run

experiment_name: RL_vs_Complementary_ColdStuck_FreqAmp_BondAlpha5_2.5M_quicktest

# Environment parameters
patterns:
  - cold_stuck
mechanism: frequency_amplifier
threshold: 0.8
max_sessions: 100
entropy: 0.1
bond_alpha: 5.0
bond_offset: 0.7
history_weight: 1.0
enable_perception: true
baseline_accuracy: 0.5

# RL parameters (PPO)
total_timesteps: 2500000  # 2.5M timesteps for ~10 hour training (quick test)
n_envs: 8
learning_rate: 0.0003
batch_size: 64
n_epochs: 10
gamma: 0.99
gae_lambda: 0.95
clip_range: 0.2
ent_coef: 0.01

# Network architecture
hidden_size: 256
lstm_hidden_size: 128

# Logging and checkpointing
log_dir: logs/RL_vs_Complementary_ColdStuck_FreqAmp_BondAlpha5_2.5M_quicktest
save_freq: 10000
eval_freq: 5000
eval_episodes: 100
seed: 42
